https://github.com/Eichhof/mesh-transformer-jax/blob/master/howto_finetune.md


python create_finetune_tfrecords.py C:/Users/wrafael/Desktop/wikipedia.txt wikipedia --preserve-data-order


https://cloud.google.com/tpu/docs/run-calculation-jax
https://cloud.google.com/tpu/docs/preemptible

1. gcloud compute tpus tpu-vm create gpt-jax --zone us-central1-a --accelerator-type v3-8 --version tpu-vm-base --preemptible

2. gcloud compute tpus tpu-vm ssh gpt-jax --zone us-central1-a

3. git clone https://github.com/Eichhof/mesh-transformer-jax.git

4. pip install "jax[tpu]==0.2.16" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html

5. export TPU_LIBRARY_PATH=/home/wrafael/.local/lib/python3.8/site-packages/libtpu/libtpu.so
https://github.com/google/jax/issues/13321

6. cd mesh-transformer-jax
pip install -r requirements.txt

7. python3 device_train.py --config=configs/triviaQA.json --tune-model-path=gs://einstein-bucket/finetune_dir_wikipedia/step_23/

python3 device_train.py --config=configs/daily_dialogues.json --tune-model-path=gs://einstein-bucket/finetune_dir_triviaQA/step_3276/

python3 device_train.py --config=configs/wow.json --tune-model-path=gs://einstein-bucket/finetune_dir_triviaQA/step_3276/



Transfer weights from bucket to NAS:
gsutil -m cp -r "gs://einstein-bucket/finetune_dir_triviaQA/step_633" \\inf.nas.ethz.ch\infk_grossm_project\digital_character\Rafael\gpt-j-6B



Transform weights on Cluster:
# module load gcc/8.2.0 python/3.8.5
# module load eth_proxy
pip install --user jax==0.2.12
pip install --user -r requirements.txt

sbatch -A ls_grossm -n 1 --time=4:00:00 --mem-per-cpu=150000 --wrap="python to_hf_weights.py --input-ckpt /nfs/inf.nas.ethz.ch/fs1201/infk_grossm_project/digital_character/Rafael/gpt-j-6B/step_633 --config ./configs/6B_roto_256.json --output-path /nfs/inf.nas.ethz.ch/fs1201/infk_grossm_project/digital_character/Rafael/gpt-j-6B/transformed --cpu --dtype fp16"