https://github.com/Eichhof/mesh-transformer-jax/blob/master/howto_finetune.md

*** Create TF records ***
python create_finetune_tfrecords.py C:/Users/wrafael/Desktop/wikipedia.txt wikipedia --preserve-data-order


*** Transfer weights ***
Transfer weights to bucket: gsutil -m cp -R LOCAL_PATH_TO/step_383500 gs://YOUR-BUCKET


*** Training on TPU ***

https://cloud.google.com/tpu/docs/run-calculation-jax
https://cloud.google.com/tpu/docs/preemptible

0. pip3 install pyOpenSSL --upgrade
   pip install -U google-cloud-storage

1. gcloud compute tpus tpu-vm create gpt-jax --zone europe-west4-a --accelerator-type v3-8 --version tpu-vm-base --preemptible

2. gcloud compute tpus tpu-vm ssh gpt-jax --zone europe-west4-a

3. git clone https://github.com/Eichhof/mesh-transformer-jax.git

4. pip install "jax[tpu]==0.2.16" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html

5. export TPU_LIBRARY_PATH=/home/wrafael/.local/lib/python3.8/site-packages/libtpu/libtpu.so
https://github.com/google/jax/issues/13321

6. cd mesh-transformer-jax
pip install -r requirements.txt

7. python3 device_train.py --config=configs/wikipedia.json --tune-model-path=gs://einstein-bucket/step_383500/

python3 device_train.py --config=configs/triviaQA.json --tune-model-path=gs://einstein-bucket/finetune_dir_wikipedia2/step_23/

python3 device_train.py --config=configs/daily_dialogues.json --tune-model-path=gs://einstein-bucket/finetune_dir_triviaQA/step_615/

python3 device_train.py --config=configs/wow.json --tune-model-path=gs://einstein-bucket/finetune_dir_triviaQA/step_615/

python3 device_train.py --config=configs/einstein.json --tune-model-path=gs://einstein-bucket/finetune_dir_wow/step_610/




gcloud compute tpus tpu-vm stop gpt-jax europe-west4-a
gcloud compute tpus tpu-vm start gpt-jax europe-west4-a
gcloud compute tpus tpu-vm delete gpt-jax europe-west4-a
gcloud compute tpus tpu-vm list --zone europe-west4-a



*** Transfer weights back ***
Transfer weights from bucket to NAS:
gsutil -m cp -r "gs://einstein-bucket/finetune_dir_triviaQA/step_633" \\inf.nas.ethz.ch\infk_grossm_project\digital_character\Rafael\gpt-j-6B



*** Transformation of weights ***

Transform weights on Cluster:
# module load gcc/8.2.0 python/3.8.5
# module load eth_proxy
pip install --user jax==0.2.12
pip install --user -r requirements.txt

sbatch -A ls_grossm -n 1 --time=4:00:00 --mem-per-cpu=150000 --wrap="python to_hf_weights.py --input-ckpt /nfs/inf.nas.ethz.ch/fs1201/infk_grossm_project/digital_character/Rafael/gpt-j-6B/finetune_dir_daily_dialogues/step_158 --config ./configs/6B_roto_256.json --output-path /nfs/inf.nas.ethz.ch/fs1201/infk_grossm_project/digital_character/Rafael/gpt-j-6B/finetune_dir_daily_dialogues/transformed --cpu --dtype fp16"